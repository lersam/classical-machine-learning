{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63ecec57",
   "metadata": {},
   "source": [
    "### Load and inspect the file ‘ASA All NBA Raw Data.csv’, which is raw NBA data for the time range 2019-10-22 to 2022-02-27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "77f26921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sweetviz as sv\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from zipfile import ZipFile\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79f7b565",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ler_s\\AppData\\Local\\Temp\\ipykernel_12352\\3735818334.py:3: DtypeWarning: Columns (68,69,70) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(z.open(\"ASA All NBA Raw Data.csv\"))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>game_date</th>\n",
       "      <th>OT</th>\n",
       "      <th>H_A</th>\n",
       "      <th>Team_Abbrev</th>\n",
       "      <th>Team_Score</th>\n",
       "      <th>Team_pace</th>\n",
       "      <th>Team_efg_pct</th>\n",
       "      <th>Team_tov_pct</th>\n",
       "      <th>Team_orb_pct</th>\n",
       "      <th>...</th>\n",
       "      <th>pf_per_minute</th>\n",
       "      <th>ts</th>\n",
       "      <th>last_60_minutes_per_game_starting</th>\n",
       "      <th>last_60_minutes_per_game_bench</th>\n",
       "      <th>PG%</th>\n",
       "      <th>SG%</th>\n",
       "      <th>SF%</th>\n",
       "      <th>PF%</th>\n",
       "      <th>C%</th>\n",
       "      <th>active_position_minutes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202270CHO</td>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DET</td>\n",
       "      <td>127</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.518</td>\n",
       "      <td>10.6</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051858</td>\n",
       "      <td>19.32</td>\n",
       "      <td>34.047024</td>\n",
       "      <td>18.329358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202270CHO</td>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DET</td>\n",
       "      <td>127</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.518</td>\n",
       "      <td>10.6</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120060</td>\n",
       "      <td>19.00</td>\n",
       "      <td>29.825758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202270CHO</td>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DET</td>\n",
       "      <td>127</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.518</td>\n",
       "      <td>10.6</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.122324</td>\n",
       "      <td>18.64</td>\n",
       "      <td>30.957143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202202270CHO</td>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DET</td>\n",
       "      <td>127</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.518</td>\n",
       "      <td>10.6</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.173410</td>\n",
       "      <td>9.88</td>\n",
       "      <td>25.828472</td>\n",
       "      <td>13.904867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202202270CHO</td>\n",
       "      <td>2022-02-27</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>DET</td>\n",
       "      <td>127</td>\n",
       "      <td>96.3</td>\n",
       "      <td>0.518</td>\n",
       "      <td>10.6</td>\n",
       "      <td>39.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090293</td>\n",
       "      <td>4.88</td>\n",
       "      <td>28.463725</td>\n",
       "      <td>25.170000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        game_id   game_date  OT H_A Team_Abbrev  Team_Score  Team_pace  \\\n",
       "0  202202270CHO  2022-02-27   1   A         DET         127       96.3   \n",
       "1  202202270CHO  2022-02-27   1   A         DET         127       96.3   \n",
       "2  202202270CHO  2022-02-27   1   A         DET         127       96.3   \n",
       "3  202202270CHO  2022-02-27   1   A         DET         127       96.3   \n",
       "4  202202270CHO  2022-02-27   1   A         DET         127       96.3   \n",
       "\n",
       "   Team_efg_pct  Team_tov_pct  Team_orb_pct  ...  pf_per_minute     ts  \\\n",
       "0         0.518          10.6          39.3  ...       0.051858  19.32   \n",
       "1         0.518          10.6          39.3  ...       0.120060  19.00   \n",
       "2         0.518          10.6          39.3  ...       0.122324  18.64   \n",
       "3         0.518          10.6          39.3  ...       0.173410   9.88   \n",
       "4         0.518          10.6          39.3  ...       0.090293   4.88   \n",
       "\n",
       "  last_60_minutes_per_game_starting last_60_minutes_per_game_bench   PG%  \\\n",
       "0                         34.047024                      18.329358   0.0   \n",
       "1                         29.825758                       0.000000   0.0   \n",
       "2                         30.957143                       0.000000   2.0   \n",
       "3                         25.828472                      13.904867   0.0   \n",
       "4                         28.463725                      25.170000  94.0   \n",
       "\n",
       "    SG%   SF%   PF%    C%  active_position_minutes  \n",
       "0   7.0  50.0  44.0   0.0                      NaN  \n",
       "1   0.0   2.0  94.0   4.0                      NaN  \n",
       "2  83.0  15.0   0.0   0.0                      NaN  \n",
       "3   0.0   0.0   2.0  98.0                      NaN  \n",
       "4   6.0   0.0   0.0   0.0                      NaN  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip_path = Path(\"local_data/ASA All NBA Raw Data.zip\")\n",
    "z = ZipFile(BytesIO(zip_path.read_bytes()))\n",
    "df = pd.read_csv(z.open(\"ASA All NBA Raw Data.csv\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585a62c9",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0525a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric columns to clean: ['OT', 'Team_Score', 'Team_pace', 'Team_efg_pct', 'Team_tov_pct', 'Team_orb_pct', 'Team_ft_rate', 'Team_off_rtg', 'Opponent_Score', 'Opponent_pace', 'Opponent_efg_pct', 'Opponent_tov_pct', 'Opponent_orb_pct', 'Opponent_ft_rate', 'Opponent_off_rtg', 'starter', 'fg', 'fga', 'fg_pct', 'fg3', 'fg3a', 'fg3_pct', 'ft', 'fta', 'ft_pct', 'orb', 'drb', 'trb', 'ast', 'stl', 'blk', 'tov', 'pf', 'pts', 'plus_minus', 'did_not_play', 'is_inactive', 'ts_pct', 'efg_pct', 'fg3a_per_fga_pct', 'fta_per_fga_pct', 'orb_pct', 'drb_pct', 'trb_pct', 'ast_pct', 'stl_pct', 'blk_pct', 'tov_pct', 'usg_pct', 'off_rtg', 'def_rtg', 'bpm', 'season', 'minutes', 'double_double', 'triple_double', 'DKP', 'FDP', 'SDP', 'DKP_per_minute', 'pf_per_minute', 'ts', 'last_60_minutes_per_game_starting', 'last_60_minutes_per_game_bench', 'PG%', 'SG%', 'SF%', 'PF%', 'C%', 'active_position_minutes']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# cleaning all numericfields from NA\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"Numeric columns to clean: {num_cols}\")\n",
    "\n",
    "for col in num_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# cleaning DKP_per_minute column: coerce non-numeric to NaN then fill with 0\n",
    "df['DKP_per_minute'] = pd.to_numeric(df['DKP_per_minute'], errors='coerce').fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cb494477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c5b0c349fe4c63919394912975716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "\n\nColumn [FDP_per_minute] has a 'mixed' inferred_type (as determined by Pandas).\nThis is is not currently supported; column types should not contain mixed data.\ne.g. only floats or strings, but not a combination.\n\nPOSSIBLE RESOLUTIONS:\nBEST -> Make sure series [FDP_per_minute] only contains a certain type of data (numerical OR string).\nOR -> Convert series [FDP_per_minute] to a string (if makes sense) so it will be picked up as CATEGORICAL or TEXT.\n     One way to do this is:\n     df['FDP_per_minute'] = df['FDP_per_minute'].astype(str)\nOR -> Convert series [FDP_per_minute] to a numerical value (if makes sense):\n     One way to do this is:\n     df['FDP_per_minute'] = pd.to_numeric(df['FDP_per_minute'], errors='coerce')\n     # (errors='coerce' will transform string values to NaN, that can then be replaced if desired; consult Pandas manual pages for more details)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m report \u001b[38;5;241m=\u001b[39m \u001b[43msv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m report\u001b[38;5;241m.\u001b[39mshow_html(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msweetviz_eda.html\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\workspace\\classical-machine-learning\\venv\\lib\\site-packages\\sweetviz\\sv_public.py:12\u001b[0m, in \u001b[0;36manalyze\u001b[1;34m(source, target_feat, feat_cfg, pairwise_analysis)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze\u001b[39m(source: Union[pd\u001b[38;5;241m.\u001b[39mDataFrame, Tuple[pd\u001b[38;5;241m.\u001b[39mDataFrame, \u001b[38;5;28mstr\u001b[39m]],\n\u001b[0;32m      9\u001b[0m             target_feat: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     10\u001b[0m             feat_cfg: FeatureConfig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     11\u001b[0m             pairwise_analysis: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 12\u001b[0m     report \u001b[38;5;241m=\u001b[39m \u001b[43msweetviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataframeReport\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_feat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mpairwise_analysis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeat_cfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m report\n",
      "File \u001b[1;32md:\\workspace\\classical-machine-learning\\venv\\lib\\site-packages\\sweetviz\\dataframe_report.py:277\u001b[0m, in \u001b[0;36mDataframeReport.__init__\u001b[1;34m(self, source, target_feature_name, compare, pairwise_analysis, fc, verbosity)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features_to_process:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# start = time.perf_counter()\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mset_description_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_features[f\u001b[38;5;241m.\u001b[39msource\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m \u001b[43msa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyze_feature_to_dictionary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;66;03m# print(f\"DONE FEATURE------> {f.source.name}\"\u001b[39;00m\n\u001b[0;32m    280\u001b[0m     \u001b[38;5;66;03m#       f\" {(time.perf_counter() - start):.2f}   {self._features[f.source.name]['type']}\")\u001b[39;00m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;66;03m# self.progress_bar.set_description_str('[FEATURES DONE]')\u001b[39;00m\n\u001b[0;32m    282\u001b[0m \u001b[38;5;66;03m# self.progress_bar.close()\u001b[39;00m\n\u001b[0;32m    283\u001b[0m \n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Wrap up summary\u001b[39;00m\n",
      "File \u001b[1;32md:\\workspace\\classical-machine-learning\\venv\\lib\\site-packages\\sweetviz\\series_analyzer.py:99\u001b[0m, in \u001b[0;36manalyze_feature_to_dictionary\u001b[1;34m(to_process)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# Determine SOURCE feature type\u001b[39;00m\n\u001b[0;32m     98\u001b[0m to_process\u001b[38;5;241m.\u001b[39msource_counts \u001b[38;5;241m=\u001b[39m get_counts(to_process\u001b[38;5;241m.\u001b[39msource)\n\u001b[1;32m---> 99\u001b[0m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_feature_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_counts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mto_process\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredetermined_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSOURCE\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m source_type \u001b[38;5;241m=\u001b[39m returned_feature_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    103\u001b[0m \u001b[38;5;66;03m# Determine COMPARED feature type & initialize\u001b[39;00m\n",
      "File \u001b[1;32md:\\workspace\\classical-machine-learning\\venv\\lib\\site-packages\\sweetviz\\type_detection.py:13\u001b[0m, in \u001b[0;36mdetermine_feature_type\u001b[1;34m(series, counts, must_be_this_type, which_dataframe)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdetermine_feature_type\u001b[39m(series: pd\u001b[38;5;241m.\u001b[39mSeries, counts: \u001b[38;5;28mdict\u001b[39m,\n\u001b[0;32m      7\u001b[0m         must_be_this_type: FeatureType, which_dataframe: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Replace infinite values with NaNs to avoid issues with histograms\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m# TODO: INFINITE VALUE HANDLING/WARNING\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# series.replace(to_replace=[np.inf, np.NINF, np.PINF], value=np.nan,\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#                inplace=True)\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue_counts_without_nan\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39minferred_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 13\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mColumn [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] has a \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m inferred_type (as determined by Pandas).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     14\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is is not currently supported; column types should not contain mixed data.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     15\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124me.g. only floats or strings, but not a combination.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     16\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPOSSIBLE RESOLUTIONS:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     17\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBEST -> Make sure series [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] only contains a certain type of data (numerical OR string).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     18\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOR -> Convert series [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to a string (if makes sense) so it will be picked up as CATEGORICAL or TEXT.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     19\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     One way to do this is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m].astype(str)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     21\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOR -> Convert series [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] to a numerical value (if makes sense):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     22\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     One way to do this is:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     23\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m] = pd.to_numeric(df[\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseries\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m], errors=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     24\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m     # (errors=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m will transform string values to NaN, that can then be replaced if desired;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     25\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m consult Pandas manual pages for more details)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m                         )\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;66;03m# TODO: must_be_this_type ENFORCING\u001b[39;00m\n\u001b[0;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m counts[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdistinct_count_without_nan\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     31\u001b[0m             \u001b[38;5;66;03m# Empty\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: \n\nColumn [FDP_per_minute] has a 'mixed' inferred_type (as determined by Pandas).\nThis is is not currently supported; column types should not contain mixed data.\ne.g. only floats or strings, but not a combination.\n\nPOSSIBLE RESOLUTIONS:\nBEST -> Make sure series [FDP_per_minute] only contains a certain type of data (numerical OR string).\nOR -> Convert series [FDP_per_minute] to a string (if makes sense) so it will be picked up as CATEGORICAL or TEXT.\n     One way to do this is:\n     df['FDP_per_minute'] = df['FDP_per_minute'].astype(str)\nOR -> Convert series [FDP_per_minute] to a numerical value (if makes sense):\n     One way to do this is:\n     df['FDP_per_minute'] = pd.to_numeric(df['FDP_per_minute'], errors='coerce')\n     # (errors='coerce' will transform string values to NaN, that can then be replaced if desired; consult Pandas manual pages for more details)\n"
     ]
    }
   ],
   "source": [
    "report = sv.analyze(df)\n",
    "report.show_html(\"sweetviz_eda.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92edfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report.show_html(\"sweetviz_eda.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acb2136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 113125\n",
      "\n",
      "Numeric fields summary (missing and zero counts/pct):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "      <th>zero_count</th>\n",
       "      <th>zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pf_per_minute</td>\n",
       "      <td>19558</td>\n",
       "      <td>17.29</td>\n",
       "      <td>19023</td>\n",
       "      <td>16.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>active_position_minutes</td>\n",
       "      <td>15412</td>\n",
       "      <td>13.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>last_60_minutes_per_game_bench</td>\n",
       "      <td>2724</td>\n",
       "      <td>2.41</td>\n",
       "      <td>7340</td>\n",
       "      <td>6.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>last_60_minutes_per_game_starting</td>\n",
       "      <td>2724</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1715</td>\n",
       "      <td>1.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PG%</td>\n",
       "      <td>148</td>\n",
       "      <td>0.13</td>\n",
       "      <td>70105</td>\n",
       "      <td>61.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Opponent_efg_pct</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Opponent_tov_pct</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Opponent_ft_rate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Opponent_off_rtg</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>season</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               column  missing_count  missing_pct  zero_count  \\\n",
       "0                       pf_per_minute          19558        17.29       19023   \n",
       "1             active_position_minutes          15412        13.62           0   \n",
       "2      last_60_minutes_per_game_bench           2724         2.41        7340   \n",
       "3   last_60_minutes_per_game_starting           2724         2.41        1715   \n",
       "4                                 PG%            148         0.13       70105   \n",
       "..                                ...            ...          ...         ...   \n",
       "65                   Opponent_efg_pct              0         0.00           0   \n",
       "66                   Opponent_tov_pct              0         0.00           0   \n",
       "67                   Opponent_ft_rate              0         0.00           0   \n",
       "68                   Opponent_off_rtg              0         0.00           0   \n",
       "69                             season              0         0.00           0   \n",
       "\n",
       "    zero_pct  \n",
       "0      16.82  \n",
       "1       0.00  \n",
       "2       6.49  \n",
       "3       1.52  \n",
       "4      61.97  \n",
       "..       ...  \n",
       "65      0.00  \n",
       "66      0.00  \n",
       "67      0.00  \n",
       "68      0.00  \n",
       "69      0.00  \n",
       "\n",
       "[70 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows with any numeric missing: 32129 (28.4%)\n",
      "\n",
      "Top 5 columns by zero_count:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>missing_count</th>\n",
       "      <th>missing_pct</th>\n",
       "      <th>zero_count</th>\n",
       "      <th>zero_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>triple_double</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112542</td>\n",
       "      <td>99.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is_inactive</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>111781</td>\n",
       "      <td>98.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OT</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106816</td>\n",
       "      <td>94.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>double_double</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>105020</td>\n",
       "      <td>92.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>did_not_play</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93597</td>\n",
       "      <td>82.74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           column  missing_count  missing_pct  zero_count  zero_pct\n",
       "9   triple_double              0          0.0      112542     99.48\n",
       "10    is_inactive              0          0.0      111781     98.81\n",
       "11             OT              0          0.0      106816     94.42\n",
       "12  double_double              0          0.0      105020     92.84\n",
       "13   did_not_play              0          0.0       93597     82.74"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Per-numeric-field summary: total missing (None/NaN) and total zeros\n",
    "import pandas as pd\n",
    "\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "total_rows = len(df)\n",
    "\n",
    "rows = []\n",
    "for c in numeric_cols:\n",
    "    missing_count = int(df[c].isnull().sum())\n",
    "    zero_count = int((df[c] == 0).sum())\n",
    "    rows.append({\n",
    "        'column': c,\n",
    "        'missing_count': missing_count,\n",
    "        'missing_pct': round(missing_count / total_rows * 100, 2),\n",
    "        'zero_count': zero_count,\n",
    "        'zero_pct': round(zero_count / total_rows * 100, 2)\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows).sort_values(['missing_count', 'zero_count'], ascending=[False, False]).reset_index(drop=True)\n",
    "print(f'Total rows: {total_rows}')\n",
    "print('\\nNumeric fields summary (missing and zero counts/pct):')\n",
    "display(summary_df)\n",
    "\n",
    "# Additional quick insights\n",
    "n_rows_with_numeric_missing = int(df[numeric_cols].isnull().any(axis=1).sum()) if numeric_cols else 0\n",
    "print(f'Rows with any numeric missing: {n_rows_with_numeric_missing} ({round(n_rows_with_numeric_missing/total_rows*100,2) if total_rows else 0}%)')\n",
    "\n",
    "if not summary_df.empty:\n",
    "    print('\\nTop 5 columns by zero_count:')\n",
    "    display(summary_df.sort_values('zero_count', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d62aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: One-hot encoding is for categorical variables, not for converting non-numeric numeric fields to zero.\n",
    "# Use pd.to_numeric(..., errors='coerce').fillna(0) to coerce non-numeric -> NaN -> 0 for numeric columns (already done).\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 1) Confirm numeric coercion (safe repeat):\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "for c in numeric_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0)\n",
    "print('Numeric coercion complete. Example types:')\n",
    "print(df[numeric_cols].dtypes.to_dict())\n",
    "\n",
    "# 2) If you WANT to one-hot encode numeric columns, do it only for a small explicit subset\n",
    "# (e.g., bucketed numeric features or numeric codes treated as categories).\n",
    "# Replace the list below with columns you intentionally treat as categorical:\n",
    "numeric_as_cat = ['example_numeric_cat_col1', 'example_numeric_cat_col2']  # <- EDIT\n",
    "numeric_as_cat = [c for c in numeric_as_cat if c in df.columns]\n",
    "\n",
    "if numeric_as_cat:\n",
    "    print('\\nOne-hot encoding these numeric-as-categorical columns:', numeric_as_cat)\n",
    "    df_onehot = pd.get_dummies(df, columns=numeric_as_cat, dummy_na=False, drop_first=False)\n",
    "    print('Resulting shape after get_dummies (sample):', df_onehot.shape)\n",
    "    display(df_onehot.head())\n",
    "else:\n",
    "    print('\\nNo numeric-as-categorical columns specified (skipping get_dummies).')\n",
    "\n",
    "# 3) Recommended: use ColumnTransformer in a pipeline to handle numeric and categorical separately\n",
    "# Example: treat numeric_features as numeric, categorical_features with OneHotEncoder\n",
    "numeric_features = df.select_dtypes(include=['number']).columns.tolist()\n",
    "categorical_features = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "cat_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', 'passthrough', numeric_features),\n",
    "    ('cat', cat_encoder, categorical_features)\n",
    "])\n",
    "\n",
    "print('\\nColumnTransformer example prepared. Use in a pipeline:')\n",
    "print(\"Pipeline([('pre', preprocessor), ('clf', YourEstimator())])\")\n",
    "\n",
    "# End of cell. If you want me to one-hot encode specific numeric columns now,\n",
    "# tell me which column names to include in numeric_as_cat and I will modify the notebook accordingly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
